{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.lookup import KeyValueTensorInitializer, StaticHashTable\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, TimeDistributed, Dropout, Bidirectional, Dense, Layer, InputSpec\n",
    "from tensorflow_addons.text import crf_log_likelihood, viterbi_decode, crf_decode\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.scheme import IOB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_layer(input_dim, output_dim, input_length, mask_zero):\n",
    "    return Embedding(input_dim = input_dim, output_dim = output_dim, input_length = input_length, mask_zero = mask_zero)\n",
    "\n",
    "def bilstm_crf(maxlen, n_tags, lstm_units, embedding_dim, n_words, mask_zero, training = True):\n",
    "    \"\"\"\n",
    "    bilstm_crf - module to build BiLSTM-CRF model\n",
    "    Inputs:\n",
    "        - input_shape : tuple\n",
    "            Tensor shape of inputs, excluding batch size\n",
    "    Outputs:\n",
    "        - output : tensorflow.keras.outputs.output\n",
    "            BiLSTM-CRF output\n",
    "    \"\"\"\n",
    "    input = Input(shape = (maxlen,))\n",
    "    # Embedding layer\n",
    "    embeddings = embedding_layer(input_dim = n_words, output_dim = embedding_dim, input_length = maxlen, mask_zero = mask_zero)\n",
    "    output = embeddings(input)\n",
    "\n",
    "    # BiLSTM layer\n",
    "    output = Bidirectional(LSTM(units = lstm_units, return_sequences = True, recurrent_dropout = 0.1))(output)\n",
    "\n",
    "    # Dense layer\n",
    "    output = TimeDistributed(Dense(n_tags, activation = 'relu'))(output)\n",
    "\n",
    "    output = CRF(n_tags, name = 'crf_layer')(output)\n",
    "    return Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 transitions=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim)\n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = transitions\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CRF, self).get_config()\n",
    "        config.update({\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'transitions': self.transitions.numpy()  # Convert the transitions to a NumPy array\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Since 'transitions' is a NumPy array, we need to convert it back to a tensor\n",
    "        transitions = tf.convert_to_tensor(config['transitions'])\n",
    "        # Create a new instance of CRF with the saved configuration\n",
    "        return cls(output_dim=config['output_dim'], sparse_target=config['sparse_target'], transitions=transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_accuracy(y_true, y_pred):\n",
    "    # -1e10 to avoid zero at sum(mask)\n",
    "    mask = K.cast(\n",
    "        K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "    shape = tf.shape(y_pred)\n",
    "    sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "    y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "    if self.sparse_target:\n",
    "        y_true = K.argmax(y_true, 2)\n",
    "    y_pred = K.cast(y_pred, 'int32')\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "    return K.sum(corrects * mask) / K.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crf_loss(y_true, y_pred):\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "    log_likelihood, self.transitions = crf_log_likelihood(\n",
    "        y_pred,\n",
    "        tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "        self.sequence_lengths,\n",
    "        transition_params=self.transitions,\n",
    "    )\n",
    "    return tf.reduce_mean(-log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model = tf.keras.models.load_model('model_teste_load', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tuples(data):\n",
    "    iterator = zip(data[\"word\"].values.tolist(),\n",
    "                  data[\"tag\"].values.tolist())\n",
    "    return [(word, tag) for word, tag in iterator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "  all_words = list(set(data[\"word\"].values))\n",
    "  all_tags = list(set(data[\"tag\"].values))\n",
    "\n",
    "  word2index = {word: idx + 2 for idx, word in enumerate(all_words)}\n",
    "\n",
    "  word2index[\"--UNKNOWN_WORD--\"] = 0\n",
    "\n",
    "  word2index[\"--PADDING--\"] = 1\n",
    "\n",
    "  index2word = {idx: word for word, idx in word2index.items()}\n",
    "\n",
    "  tag2index = {tag: idx + 1 for idx, tag in enumerate(all_tags)}\n",
    "  tag2index[\"--PADDING--\"] = 0\n",
    "\n",
    "  index2tag = {idx: word for word, idx in tag2index.items()}\n",
    "\n",
    "  return word2index, index2word, tag2index, index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(reports, word2index, tag2index):\n",
    "  contents = []\n",
    "  labels = []\n",
    "  for report in reports:\n",
    "    content = []\n",
    "    label = []\n",
    "    for i in range(len(report)):\n",
    "      word, tag = report[i]\n",
    "      word_idx = word2index.get(word, 0)\n",
    "      tag_idx = tag2index.get(tag, 0)\n",
    "      content.append(word_idx)\n",
    "      label.append(tag_idx)\n",
    "\n",
    "    contents.append(content)\n",
    "    labels.append(label)\n",
    "\n",
    "  \"\"\"\n",
    "  padding the array with max_sentence_size\n",
    "  pad_sequences(sequences, maxlen=None, dtype=\"int32\", padding=\"pre\", truncating=\"pre\", value=0.0,):\n",
    "  the maxlen argument if provided, or the length of the longest sequence in the list.\n",
    "  \"\"\"\n",
    "\n",
    "  max_sentence_size = 512\n",
    "  contents = tf.keras.preprocessing.sequence.pad_sequences(contents, maxlen=max_sentence_size, padding='post', value=1)\n",
    "  labels = tf.keras.preprocessing.sequence.pad_sequences(labels, maxlen=max_sentence_size, padding='post')\n",
    "\n",
    "  tag_size = len(tag2index)\n",
    "\n",
    "  labels_categorical = [tf.keras.utils.to_categorical(i, num_classes=tag_size) for i in labels]\n",
    "  labels_categorical = np.asarray(labels_categorical)\n",
    "\n",
    "  return contents, labels, labels_categorical, max_sentence_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_word_test_sentences_and_tags(index2tag, index2word, X_test, y_test):\n",
    "\n",
    "    test_sentences= []\n",
    "    test_tags = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        aux_tag = []\n",
    "\n",
    "        report = \"\"\n",
    "        sentence = X_test[i]\n",
    "        tags = y_test[i]\n",
    "\n",
    "        for j in range(len(sentence)):\n",
    "            word = sentence[j]\n",
    "            tag = tags[j]\n",
    "            int_tag = np.where(tag == int(1))\n",
    "\n",
    "            if str(index2word[word]) != '--PADDING--':\n",
    "                report = report + \" \" + str(index2word[word])\n",
    "                aux_tag.append(index2tag[int(int_tag[0][0])])\n",
    "\n",
    "        test_sentences.append(report)\n",
    "        test_tags.append(aux_tag)\n",
    "\n",
    "    return test_sentences, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_df_model_previous(test_sentences, test_tags, model, word2index, index2tag, MAX_SENTENCE):\n",
    "\n",
    "    test_df = pd.DataFrame(columns = ['report', 'word', 'tag', 'tag_pred'])\n",
    "\n",
    "    for i in range (len(test_sentences)):\n",
    "        sentence = test_sentences[i]\n",
    "        tags = test_tags[i]\n",
    "        \n",
    "        sentence = sentence.split()\n",
    "        padded_sentence = sentence + [word2index[\"--PADDING--\"]] * (MAX_SENTENCE - len(sentence))\n",
    "        padded_sentence = [word2index.get(w, 0) for w in padded_sentence]\n",
    "\n",
    "        pred = model.predict(np.array([padded_sentence]))\n",
    "        pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "        if i < 10:\n",
    "            retval = \"\"\n",
    "            for w, t, p in zip(sentence, tags, pred[0]):\n",
    "                retval = retval + \"{:25}: {:10} {:5}\".format(w, t, index2tag[p]) + \"\\n\"\n",
    "                aux_dict = {'report': ('report_0' + str(i)), 'word': w, 'tag' : t, 'tag_pred' : index2tag[p]}\n",
    "                df_new_row = pd.DataFrame([aux_dict])\n",
    "                test_df = pd.concat([test_df, df_new_row])\n",
    "\n",
    "\n",
    "        else:\n",
    "            retval = \"\"\n",
    "            for w, t, p in zip(sentence, tags, pred[0]):\n",
    "                retval = retval + \"{:25}: {:10} {:5}\".format(w, t, index2tag[p]) + \"\\n\"\n",
    "                aux_dict = {'report': ('report_' + str(i)), 'word': w, 'tag' : t, 'tag_pred' : index2tag[p]}\n",
    "                df_new_row = pd.DataFrame([aux_dict])\n",
    "                test_df = pd.concat([test_df, df_new_row])\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('laudos_1_963_iob.csv', encoding= 'utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test_mod_df.csv', encoding= 'utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index, index2word, tag2index, index2tag = build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = data_test.groupby(\"report\").apply(to_tuples).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_sequences, test_tag_sequences, test_tag_sequences_categorical, max_len = tokenize(reports, word2index, tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_tags = number_to_word_test_sentences_and_tags(index2tag, index2word, test_text_sequences, test_tag_sequences_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = cur_dir+'\\\\models\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_00 = tf.keras.models.load_model(models_dir+'model_00', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "result_df_model_00 = result_df_model_previous(test_sentences, test_tags, loaded_model_00, word2index, index2tag, max_len)\n",
    "result_df_model_00.to_csv(\"result_df_model_00.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_00 = tf.keras.models.load_model(models_dir+'model_00', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_01 = tf.keras.models.load_model(models_dir+'model_01', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_02 = tf.keras.models.load_model(models_dir+'model_02', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_03 = tf.keras.models.load_model(models_dir+'model_03', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_04 = tf.keras.models.load_model(models_dir+'model_04', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_05 = tf.keras.models.load_model(models_dir+'model_05', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_06 = tf.keras.models.load_model(models_dir+'model_06', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_07 = tf.keras.models.load_model(models_dir+'model_07', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_08 = tf.keras.models.load_model(models_dir+'model_08', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_09 = tf.keras.models.load_model(models_dir+'model_09', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_10 = tf.keras.models.load_model(models_dir+'model_10', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_11 = tf.keras.models.load_model(models_dir+'model_11', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_12 = tf.keras.models.load_model(models_dir+'model_12', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_13 = tf.keras.models.load_model(models_dir+'model_13', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_14 = tf.keras.models.load_model(models_dir+'model_14', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_15 = tf.keras.models.load_model(models_dir+'model_15', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_16 = tf.keras.models.load_model(models_dir+'model_16', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_17 = tf.keras.models.load_model(models_dir+'model_17', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_18 = tf.keras.models.load_model(models_dir+'model_18', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_19 = tf.keras.models.load_model(models_dir+'model_19', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_20 = tf.keras.models.load_model(models_dir+'model_20', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_21 = tf.keras.models.load_model(models_dir+'model_21', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_22 = tf.keras.models.load_model(models_dir+'model_22', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_23 = tf.keras.models.load_model(models_dir+'model_23', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_24 = tf.keras.models.load_model(models_dir+'model_24', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_25 = tf.keras.models.load_model(models_dir+'model_25', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n",
    "loaded_model_26 = tf.keras.models.load_model(models_dir+'model_26', custom_objects={'CRF': CRF, 'viterbi_accuracy': viterbi_accuracy, 'crf_loss': crf_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_model_00 = result_df_model_previous(test_sentences, test_tags, loaded_model_00, word2index, index2tag, max_len)\n",
    "result_df_model_00.to_csv(\"result_df_model_00.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_01 = result_df_model_previous(test_sentences, test_tags, loaded_model_01, word2index, index2tag, max_len)\n",
    "result_df_model_01.to_csv(\"result_df_model_01.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_02 = result_df_model_previous(test_sentences, test_tags, loaded_model_02, word2index, index2tag, max_len)\n",
    "result_df_model_02.to_csv(\"result_df_model_02.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_03 = result_df_model_previous(test_sentences, test_tags, loaded_model_03, word2index, index2tag, max_len)\n",
    "result_df_model_03.to_csv(\"result_df_model_03.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_04 = result_df_model_previous(test_sentences, test_tags, loaded_model_04, word2index, index2tag, max_len)\n",
    "result_df_model_04.to_csv(\"result_df_model_04.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_05 = result_df_model_previous(test_sentences, test_tags, loaded_model_05, word2index, index2tag, max_len)\n",
    "result_df_model_05.to_csv(\"result_df_model_05.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_06 = result_df_model_previous(test_sentences, test_tags, loaded_model_06, word2index, index2tag, max_len)\n",
    "result_df_model_06.to_csv(\"result_df_model_06.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_07 = result_df_model_previous(test_sentences, test_tags, loaded_model_07, word2index, index2tag, max_len)\n",
    "result_df_model_07.to_csv(\"result_df_model_07.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_08 = result_df_model_previous(test_sentences, test_tags, loaded_model_08, word2index, index2tag, max_len)\n",
    "result_df_model_08.to_csv(\"result_df_model_08.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_09 = result_df_model_previous(test_sentences, test_tags, loaded_model_09, word2index, index2tag, max_len)\n",
    "result_df_model_09.to_csv(\"result_df_model_09.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_10 = result_df_model_previous(test_sentences, test_tags, loaded_model_10, word2index, index2tag, max_len)\n",
    "result_df_model_10.to_csv(\"result_df_model_10.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_11 = result_df_model_previous(test_sentences, test_tags, loaded_model_11, word2index, index2tag, max_len)\n",
    "result_df_model_11.to_csv(\"result_df_model_11.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_12 = result_df_model_previous(test_sentences, test_tags, loaded_model_12, word2index, index2tag, max_len)\n",
    "result_df_model_12.to_csv(\"result_df_model_12.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_13 = result_df_model_previous(test_sentences, test_tags, loaded_model_13, word2index, index2tag, max_len)\n",
    "result_df_model_13.to_csv(\"result_df_model_13.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_14 = result_df_model_previous(test_sentences, test_tags, loaded_model_14, word2index, index2tag, max_len)\n",
    "result_df_model_14.to_csv(\"result_df_model_14.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_15 = result_df_model_previous(test_sentences, test_tags, loaded_model_15, word2index, index2tag, max_len)\n",
    "result_df_model_15.to_csv(\"result_df_model_15.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_16 = result_df_model_previous(test_sentences, test_tags, loaded_model_16, word2index, index2tag, max_len)\n",
    "result_df_model_16.to_csv(\"result_df_model_16.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_17 = result_df_model_previous(test_sentences, test_tags, loaded_model_17, word2index, index2tag, max_len)\n",
    "result_df_model_17.to_csv(\"result_df_model_17.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_18 = result_df_model_previous(test_sentences, test_tags, loaded_model_18, word2index, index2tag, max_len)\n",
    "result_df_model_18.to_csv(\"result_df_model_18.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_19 = result_df_model_previous(test_sentences, test_tags, loaded_model_19, word2index, index2tag, max_len)\n",
    "result_df_model_19.to_csv(\"result_df_model_19.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_20 = result_df_model_previous(test_sentences, test_tags, loaded_model_20, word2index, index2tag, max_len)\n",
    "result_df_model_20.to_csv(\"result_df_model_20.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_21 = result_df_model_previous(test_sentences, test_tags, loaded_model_21, word2index, index2tag, max_len)\n",
    "result_df_model_21.to_csv(\"result_df_model_21.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_22 = result_df_model_previous(test_sentences, test_tags, loaded_model_22, word2index, index2tag, max_len)\n",
    "result_df_model_22.to_csv(\"result_df_model_22.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_23 = result_df_model_previous(test_sentences, test_tags, loaded_model_23, word2index, index2tag, max_len)\n",
    "result_df_model_23.to_csv(\"result_df_model_23.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_24 = result_df_model_previous(test_sentences, test_tags, loaded_model_24, word2index, index2tag, max_len)\n",
    "result_df_model_24.to_csv(\"result_df_model_24.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_25 = result_df_model_previous(test_sentences, test_tags, loaded_model_25, word2index, index2tag, max_len)\n",
    "result_df_model_25.to_csv(\"result_df_model_25.csv\", encoding='utf-8')\n",
    "\n",
    "result_df_model_26 = result_df_model_previous(test_sentences, test_tags, loaded_model_26, word2index, index2tag, max_len)\n",
    "result_df_model_26.to_csv(\"result_df_model_26.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = []\n",
    "results_by_model = []\n",
    "results_by_model_by_tag = []\n",
    "\n",
    "for filename in filenames:\n",
    "    f = os.path.join(current_directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        print(f)\n",
    "\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "\n",
    "    sentences = data.groupby(\"report\").apply(to_tuples).tolist()\n",
    "    texts, tags, tags_pred = tuple_2_list(sentences)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(filename)\n",
    "    result_dict = classification_report(tags, tags_pred, mode=\"strict\", scheme=IOB2, zero_division=False)\n",
    "    print(result_dict)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
