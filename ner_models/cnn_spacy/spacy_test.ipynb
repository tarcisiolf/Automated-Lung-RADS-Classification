{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "from spacy.util import decaying\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.training.example import Example\n",
    "from spacy.training import biluo_tags_to_offsets\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import srsly\n",
    "import typer\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converter Formato DataFrame to Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/df_train_tokens_labeled_iob_bert_format_full.csv\", encoding=\"utf-8\")\n",
    "df_test = pd.read_csv(\"data/df_test_tokens_labeled_iob_bert_format_full.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_2_spacy_format(df):\n",
    "    spacy_format_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        entities = []\n",
    "        tokens = row['text'].split()\n",
    "        labels = row['iob_labels'].split()\n",
    "        start = 0\n",
    "        entity_label = None\n",
    "        for token, label in zip(tokens, labels):\n",
    "            end = start + len(token)\n",
    "            if label != 'O':\n",
    "                label = label.replace('B-', '').replace('I-', '').upper()\n",
    "                if label != entity_label:\n",
    "                    entity_label = label\n",
    "                    entities.append((start, end, label))\n",
    "            start = end + 1  \n",
    "        spacy_format_data.append((text, {\"entities\": entities}))\n",
    "    return spacy_format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spacy_format = bert_2_spacy_format(df_train)\n",
    "test_spacy_format = bert_2_spacy_format(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(data, iterations):\n",
    "    nlp = spacy.blank(\"pt\")  \n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "    for _, annotations in data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        #dropout = decaying(0.6, 0.2, 1e-4)\n",
    "        dropout = decaying(0.2, 1e-4)\n",
    "\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            losses = {}\n",
    "            random.shuffle(data)\n",
    "            batches = minibatch(data, size=compounding(4.0, 32.0, 1.001))\n",
    "\n",
    "            for batch in batches:\n",
    "                examples = []\n",
    "                for text, annotation in batch:\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotation)\n",
    "                    examples.append(example)\n",
    "                nlp.update(examples, losses=losses)\n",
    "            print(\"Iteration:\", itn, \"Loss:\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_spacy(train_spacy_format, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = \"spacy_model_cnn_mod\"\n",
    "trained_model.to_disk(modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile_load = spacy.load('spacy_model_cnn_mod') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(modelfile, ACC):\n",
    "    nlp = modelfile\n",
    "    examples = []\n",
    "    for input_, annot in ACC:\n",
    "        #print(input)\n",
    "        doc = nlp.make_doc(input_)\n",
    "        example = Example.from_dict(doc, annot)\n",
    "        examples.append(example)\n",
    "    scorer = nlp.evaluate(examples)\n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(modelfile_load, test_spacy_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_results = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_results.to_csv(\"results_spacy_model_mod.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
